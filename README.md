<div align="center">

# âš½ ETL Football â€“ Databricks, Azure & Power BI
### Arquitectura Medallion en Azure Databricks

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com/)
[![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![Power BI](https://img.shields.io/badge/PowerBI-F2C811?style=for-the-badge&logo=power-bi&logoColor=black)](https://www.microsoft.com/es-es/power-platform/products/power-bi)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/features/actions)

*Pipeline automatizado de datos para anÃ¡lisis de clubes de fÃºtbol con arquitectura de tres capas y despliegue continuo*

</div>

---

## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline ETL completo utilizando la arquitectura Medallion (Bronze, Silver, Gold) en Azure Databricks con PySpark. El objetivo es procesar datos desde mÃºltiples fuentes (Azure Data Lake, Blob Storage, SQL Database, CosmosDB) y disponibilizarlos para anÃ¡lisis en Power BI.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ”„ **ETL Automatizado** - Pipeline completo con despliegue automÃ¡tico via GitHub Actions
- ğŸ—ï¸ **Arquitectura Medallion** - SeparaciÃ³n clara de capas Bronze â†’ Silver â†’ Gold
- ğŸ“Š **Modelo Dimensional** - Star Schema optimizado para anÃ¡lisis de negocio
- ğŸš€ **CI/CD Integrado** - Deploy automÃ¡tico en cada push a master
- ğŸ“ˆ **Power BI** - VisualizaciÃ³n
- âš¡ **Delta Lake** - ACID transactions y time travel capabilities
- ğŸ”” **Monitoreo** - Notificaciones automÃ¡ticas y logs detallados

---

## ğŸ›ï¸ Arquitectura

### Flujo de Datos

```
ğŸ“„ Azure Data Lake + Blob Storage + Azure SQL DataBase (Raw Data)
    â†“
ğŸ¥‰ Bronze Layer (Ingesta de datos)
    â†“
ğŸ¥ˆ Silver Layer (Limpieza + Transformacion + Modelo Dimensional)
    â†“
ğŸ¥‡ Gold Layer (Carga + Agregaciones de Negocio)
    â†“
ğŸ“Š Power BI (VisualizaciÃ³n)
```

![Texto descriptivo](arquitectura.jpg)


### ğŸ“¦ Capas del Pipeline

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¥‰ Bronze Layer
**PropÃ³sito**: Zona de aterrizaje

**Tablas**: 
- `clubs` 
- `games` 
- `players`

**CaracterÃ­sticas**:
- âœ… Datos sin procesar, como vienen del origen
- âœ… Timestamp de ingesta
- âœ… PreservaciÃ³n histÃ³rica
- âœ… Sin validaciones

</td>
<td width="33%" valign="top">

#### ğŸ¥ˆ Silver Layer
**PropÃ³sito**: Modelo dimensional

**Tablas**:
- `club_performance`
- `player_market`
- `match_analysis`

**CaracterÃ­sticas**:
- âœ… Star Schema
- âœ… Datos normalizados
- âœ… Validaciones completas

</td>
<td width="33%" valign="top">

#### ğŸ¥‡ Gold Layer
**PropÃ³sito**: Analytics-ready

**Tablas**:
- dbo.tbl_club_performance      : Rendimiento de Clubes por Temporada
- dbo.tbl_player_market         : Valor de Mercado y Perfil de Jugadores
- dbo.tbl_match_analysis        : AnÃ¡lisis de Partidos y Asistencia

**CaracterÃ­sticas**:
- âœ… Pre-agregados
- âœ… Optimizado para BI
- âœ… Performance mÃ¡ximo
- âœ… Actualizaciones automÃ¡ticas

</td>
</tr>
</table>

---

## ğŸ“ Estructura del Proyecto

```
etl-football/
â”‚
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“‚ workflows/
â”‚       â””â”€â”€ ğŸ“„ deploy_dev_to_prod.yml    # Pipeline CI/CD deploy a certification workspace databricks
â”œâ”€â”€ ğŸ“‚ process/
â”‚   â”œâ”€â”€ ğŸ Ingest players data.py    # Bronze layer
â”‚   â”œâ”€â”€ ğŸ Ingest clubs data.py      # Bronze Layer
â”‚   â”œâ”€â”€ ğŸ Ingest games data.py      # Bronze Layer
â”‚   â”œâ”€â”€ ğŸ Transform.py              # Silver Layer
â”‚   â””â”€â”€ ğŸ Load.py                   # Gold Layer
â”‚   â””â”€â”€ ğŸ Preparacion_Ambiente.py   # Create Schema, Tables, External location
â”œâ”€â”€ ğŸ“‚ security/
|   â”œâ”€â”€ ğŸ Permissions.py            # Sql Grant
â”œâ”€â”€ ğŸ“‚ reversion/
|   â”œâ”€â”€ ğŸ revoke.py               # Revoke permissions
â”œâ”€â”€ ğŸ“‚ dashboards/                 # Power BI Dashboards 
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | PropÃ³sito |
|:----------:|:----------|
| ![ADLS](https://img.shields.io/badge/ADLS_Gen2-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white) | Data Lake para almacenamiento persistente |
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | Motor de procesamiento distribuido Spark |
| ![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=flat-square&logo=delta&logoColor=white) | Storage layer con ACID transactions |
| ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) | Framework de transformaciÃ³n de datos |
| ![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white) | AutomatizaciÃ³n CI/CD |
| ![Power BI](https://img.shields.io/badge/PowerBI-F2C811?style=for-the-badge&logo=power-bi&logoColor=black) |  VisualizaciÃ³n |

</div>

---

## âš™ï¸ Prerequisitos

- â˜ï¸ Azure Databricks
- ğŸ’» Workspace de Databricks configurado
- ğŸ–¥ï¸ Cluster activo
- ğŸ“¦ Azure Data Lake Storage Gen2
- ğŸ“¦ Azure Blob Storage
- ğŸ“¦ Azure SQL Database
- ğŸ“¦ Azure Key Vault (para secretos)
- ğŸ“Š Power BI Desktop (opcional para visualizaciÃ³n)
- ğŸ™ Cuenta de GitHub con permisos de administrador

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio

```bash
git clone https://github.com/HenryRodriguezM/football.git
cd football
```

### 2ï¸âƒ£ Configurar Databricks Token

1. Ir a Databricks Workspace
2. **User Settings** â†’ **Developer** â†’ **Access Tokens**
3. Click en **Generate New Token**
4. Configurar:
   - **Comment**: `GitHub CI/CD`
   - **Lifetime**: `90 days`
5. âš ï¸ Copiar y guardar el token

### 3ï¸âƒ£ Configurar GitHub Secrets

Ir al menu del repositorio: **Settings** â†’ **Secrets and variables** â†’ **Actions**

| Secret Name | Valor Ejemplo |
|------------|---------------|
| `DATABRICKS_HOST` | `https://adb-xxxxx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | `dapi_xxxxxxxxxxxxxxxx` |

### 4ï¸âƒ£ Verificar Storage Configuration

```python
storage_path = "abfss://raw@adlsmartdata2026.dfs.core.windows.net/"
```

<div align="center">

âœ… **Â¡ConfiguraciÃ³n completa!**

</div>

---

## ğŸ’» Uso

### ğŸ”„ Despliegue AutomÃ¡tico (Recomendado)

```bash
git add .
git commit -m "âœ¨ feat: mejoras en pipeline"
git push origin master
```

**GitHub Actions ejecutarÃ¡**:
- ğŸ“¤ Deploy de notebooks a `/Production/ETL-FOOTBALL`
- ğŸ”§ CreaciÃ³n del workflow `WF_FOOTBALL`
- â–¶ï¸ EjecuciÃ³n completa:  Bronze â†’ Silver â†’ Gold
- ğŸ“§ Notificaciones de resultados

### ğŸ–±ï¸ Despliegue Manual desde GitHub

1. Ir al tab **Actions** en GitHub
2. Seleccionar **Deploy ETL Apple Sales And Warranty**
3. Click en **Run workflow**
4. Seleccionar rama `main`
5. Click en **Run workflow**

### ğŸ”§ EjecuciÃ³n Local en Databricks

Navegar a `/Production/ETL-Football` y ejecutar en orden:

```
- Preparacion_Ambiente.py         â†’ Crear esquema
- Ingest clubs data.py            â†’ Bronze Layer
- Ingest players data.py          â†’ Bronze Layer
- Ingest games data.py            â†’ Bronze Layer
- Transform.py                    â†’ Silver Layer
- Load.py                         â†’ Gold Layer
```

---


## ğŸ”„ CI/CD

### Pipeline de GitHub Actions

```yaml
Workflow: Deploy ETL Apple Sales And Warranty
â”œâ”€â”€ Deploy notebooks â†’ /Production/ETL-FOOTBALL
â”œâ”€â”€ Eliminar workflow antiguo (si existe)
â”œâ”€â”€ Buscar cluster configurado
â”œâ”€â”€ Crear nuevo workflow con 4 tareas
â”œâ”€â”€ Ejecutar pipeline automÃ¡ticamente
â””â”€â”€ Monitorear y notificar resultados
```

### ğŸ”„  Workflow Databricks
![Texto descriptivo](CICD_ETL_FOOTBALL.png)
```


â° Schedule: Diario 8:00 AM (Lima)
â±ï¸ Timeout total: 4 horas
 ğŸ”’ Max concurrent runs: 1
â° Notificaciones: 
      success: rodriguez.montero.henry@outlook.com
      failed:  rodriguez.montero.henry@outlook.com
```

---

## ğŸ“ˆ Dashboards
https://github.com/HenryRodriguezM/football/tree/main/dashboard

## ğŸ” Monitoreo

### En Databricks

**Workflows**:
- Ir a **Jobs & Pipelines** en el menÃº izquierdo
- Buscar `ETL_Football`
- Ver historial de ejecuciones

**Logs por Tarea**:
- Click en una ejecuciÃ³n especÃ­fica
- Click en cada tarea para ver logs detallados
- Revisar stdout/stderr en caso de errores

### En GitHub Actions

- Tab **Actions** del repositorio
- Ver historial de workflows
- Click en ejecuciÃ³n especÃ­fica para detalles
- Revisar logs de cada step

---

## ğŸ‘¤ Autor

<div align="center">

### Henry Herik Rodriguez Montero

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/henry-rodriguez-7b273169/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/HenryRodriguezM)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:henryrm33@gmail.com
)

**Data Engineering** | **Azure Databricks** | **Delta Lake** | **CI/CD**

</div>

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

<div align="center">

**Proyecto**: Data Engineering - Arquitectura Medallion  
**TecnologÃ­a**: Azure Databricks + Delta Lake + CI/CD  
**Ãšltima actualizaciÃ³n**: 2026


</div>